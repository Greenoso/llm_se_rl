{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aafb317-6060-4ab4-9358-73edee4b68c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">208</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">205 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">206 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">207 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span> == <span style=\"color: #808000; text-decoration-color: #808000\">\"__main__\"</span>:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>208 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>hparams = {} <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(sys.argv) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> json.loads(sys.argv[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>])                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">209 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">210 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>main(hparams)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">211 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/root/miniconda3/lib/python3.8/json/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">357</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">loads</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">354 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> object_hook <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">355 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>parse_int <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> parse_float <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">356 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>parse_constant <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> object_pairs_hook <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> kw):              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>357 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _default_decoder.decode(s)                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">358 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">359 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span> = JSONDecoder                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">360 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> object_hook <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/root/miniconda3/lib/python3.8/json/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">decoder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">337</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decode</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">334 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">containing a JSON document).</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">335 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">336 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>337 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>obj, end = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.raw_decode(s, idx=_w(s, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>).end())                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">338 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>end = _w(s, end).end()                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">339 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> end != <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(s):                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">340 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> JSONDecodeError(<span style=\"color: #808000; text-decoration-color: #808000\">\"Extra data\"</span>, s, end)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/root/miniconda3/lib/python3.8/json/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">decoder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">355</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">raw_decode</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">352 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">353 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>obj, end = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scan_once(s, idx)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">354 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">StopIteration</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> err:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>355 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> JSONDecodeError(<span style=\"color: #808000; text-decoration-color: #808000\">\"Expecting value\"</span>, s, err.value) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">356 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> obj, end                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">357 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">JSONDecodeError: </span>Expecting value: line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> column <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"font-weight: bold\">(</span>char <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m208\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m205 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m206 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m207 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m208 \u001b[2m│   \u001b[0mhparams = {} \u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(sys.argv) == \u001b[94m1\u001b[0m \u001b[94melse\u001b[0m json.loads(sys.argv[\u001b[94m1\u001b[0m])                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m209 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m210 \u001b[0m\u001b[2m│   \u001b[0mmain(hparams)                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m211 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/root/miniconda3/lib/python3.8/json/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m357\u001b[0m in \u001b[92mloads\u001b[0m                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m354 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m (\u001b[96mcls\u001b[0m \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m object_hook \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m355 \u001b[0m\u001b[2m│   │   │   \u001b[0mparse_int \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m parse_float \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m356 \u001b[0m\u001b[2m│   │   │   \u001b[0mparse_constant \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m object_pairs_hook \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m kw):              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m357 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _default_decoder.decode(s)                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m358 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mcls\u001b[0m \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m359 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mcls\u001b[0m = JSONDecoder                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m360 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m object_hook \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/root/miniconda3/lib/python3.8/json/\u001b[0m\u001b[1;33mdecoder.py\u001b[0m:\u001b[94m337\u001b[0m in \u001b[92mdecode\u001b[0m                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mcontaining a JSON document).\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m335 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m336 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m337 \u001b[2m│   │   \u001b[0mobj, end = \u001b[96mself\u001b[0m.raw_decode(s, idx=_w(s, \u001b[94m0\u001b[0m).end())                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m338 \u001b[0m\u001b[2m│   │   \u001b[0mend = _w(s, end).end()                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m339 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m end != \u001b[96mlen\u001b[0m(s):                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m340 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m JSONDecodeError(\u001b[33m\"\u001b[0m\u001b[33mExtra data\u001b[0m\u001b[33m\"\u001b[0m, s, end)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/root/miniconda3/lib/python3.8/json/\u001b[0m\u001b[1;33mdecoder.py\u001b[0m:\u001b[94m355\u001b[0m in \u001b[92mraw_decode\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m352 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m353 \u001b[0m\u001b[2m│   │   │   \u001b[0mobj, end = \u001b[96mself\u001b[0m.scan_once(s, idx)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m354 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mStopIteration\u001b[0m \u001b[94mas\u001b[0m err:                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m355 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m JSONDecodeError(\u001b[33m\"\u001b[0m\u001b[33mExpecting value\u001b[0m\u001b[33m\"\u001b[0m, s, err.value) \u001b[94mfrom\u001b[0m \u001b[94mNone\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m356 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m obj, end                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m357 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mJSONDecodeError: \u001b[0mExpecting value: line \u001b[1;36m1\u001b[0m column \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0mchar \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from typing import Dict, List\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration,AutoModelForCausalLM\n",
    "\n",
    "\n",
    "\n",
    "import trlx\n",
    "from trlx.data.configs import (\n",
    "    ModelConfig,\n",
    "    OptimizerConfig,\n",
    "    SchedulerConfig,\n",
    "    TokenizerConfig,\n",
    "    TrainConfig,\n",
    "    TRLConfig,\n",
    ")\n",
    "from trlx.models.modeling_ppo import PPOConfig\n",
    "\n",
    "from trlx.models.modeling_ppo import (\n",
    "    AutoModelForCausalLMWithHydraValueHead,\n",
    "    AutoModelForCausalLMWithValueHead,\n",
    "    AutoModelForSeq2SeqLMWithHydraValueHead,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "default_config = TRLConfig(\n",
    "    train=TrainConfig(\n",
    "        seq_length=1024,\n",
    "        epochs=4,\n",
    "        total_steps=6000,\n",
    "        batch_size=4,\n",
    "        checkpoint_interval=256,\n",
    "        eval_interval=40,\n",
    "        pipeline=\"PromptPipeline\",\n",
    "        trainer=\"AcceleratePPOTrainer\",\n",
    "        save_best=False,\n",
    "        tracker=\"wandb\",\n",
    "        checkpoint_dir='/root/autodl-tmp/msc_ml/t5_large_checkpoints'\n",
    "    ),\n",
    "    model=ModelConfig(\n",
    "        model_path=\"/root/autodl-tmp/flan-t5-large\",\n",
    "        num_layers_unfrozen=-1,\n",
    "        model_arch_type=\"seq2seq\",\n",
    "    ),\n",
    "    tokenizer=TokenizerConfig(\n",
    "        tokenizer_path=\"/root/autodl-tmp/flan-t5-large\",\n",
    "        padding_side=\"right\",\n",
    "        truncation_side=\"right\",\n",
    "    ),\n",
    "    optimizer=OptimizerConfig(\n",
    "        name=\"adamw\",\n",
    "        kwargs={\n",
    "            \"lr\": 1.0e-4,\n",
    "            \"betas\": [0.9, 0.999],\n",
    "            \"eps\": 1.0e-8,\n",
    "            \"weight_decay\": 1.0e-6,\n",
    "        },\n",
    "    ),\n",
    "    scheduler=SchedulerConfig(\n",
    "        name=\"cosine_annealing\",\n",
    "        kwargs={\n",
    "            \"T_max\": 100000,\n",
    "            \"eta_min\": 5.0e-5,\n",
    "        },\n",
    "    ),\n",
    "    method=PPOConfig(\n",
    "        name=\"PPOConfig\",\n",
    "        ### reduce rollouts due to small dataset\n",
    "        num_rollouts=128,\n",
    "        chunk_size=12,\n",
    "        ppo_epochs=4,\n",
    "        init_kl_coef=0.05,\n",
    "        target=6,\n",
    "        horizon=1000,\n",
    "        gamma=0.99,\n",
    "        lam=0.95,\n",
    "        cliprange=0.2,\n",
    "        cliprange_value=0.2,\n",
    "        vf_coef=1,\n",
    "        scale_reward=None,\n",
    "        ref_mean=None,\n",
    "        ref_std=None,\n",
    "        cliprange_reward=10,\n",
    "        gen_kwargs={\n",
    "            \"max_new_tokens\": 128,\n",
    "            \"do_sample\": True,\n",
    "            \"top_k\": 50,\n",
    "            \"top_p\": 0.95,\n",
    "            \"eos_token_id\": T5Tokenizer.from_pretrained(\"/root/autodl-tmp/flan-t5-large\").eos_token_id,\n",
    "            \"temperature\": 1.0,\n",
    "        },\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def main(hparams={}):\n",
    "    config = TRLConfig.update(default_config, hparams)\n",
    "\n",
    "\n",
    "    \n",
    "    #########################################b\n",
    "    \n",
    "    ### reward_se\n",
    "    def reward_se( prompts: List[str], outputs: List[str], **kwargs) -> List[float]:\n",
    "\n",
    "        rewards = []\n",
    "        for q, a in zip(prompts, outputs):\n",
    "            feedback_prompt = f'Is the answer to the question correct? The question is: {q}. The answer is: {a}'\n",
    "            feedback = se_generator(feedback_prompt)[0]['generated_text']  # Assuming 'model' is your trained T5 model\n",
    "            feedback = feedback.lower().strip()\n",
    "            print(feedback)\n",
    "            reward = 0.0 \n",
    "            if 'yes' in feedback:\n",
    "                reward = 1.0 \n",
    "                \n",
    "            elif 'no' in feedback:\n",
    "                reward = -1.0\n",
    "\n",
    "            rewards.append(reward)\n",
    "        return rewards\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### metric_se\n",
    "\n",
    "    \n",
    "    def metric_se(samples: List[str], prompts: List[str], outputs: List[str]) -> Dict[str, List[float]]:\n",
    "        match=[]\n",
    "        \n",
    "        for i,prompt in enumerate(prompts):\n",
    "\n",
    "            index = prompt_all_new.index(prompt)\n",
    "            if outputs[i].lower().strip()==answer_all[index].lower().strip():\n",
    "                is_correct=1.0\n",
    "            else:\n",
    "                is_correct=0.0\n",
    "                \n",
    "            match.append(is_correct)\n",
    "\n",
    "        return {\"Answer Matching\": match}\n",
    "    \n",
    "    ###########################################e\n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################b\n",
    "    # Load the model\n",
    "    model_se = T5ForConditionalGeneration.from_pretrained(\"/root/autodl-tmp/flan-t5-large\")\n",
    "\n",
    "    # Load the tokenizer\n",
    "    tokenizer_se = AutoTokenizer.from_pretrained(\"/root/autodl-tmp/flan-t5-large\")\n",
    "\n",
    "    # Create the pipeline\n",
    "    se_generator = pipeline(\"text2text-generation\", model=model_se, tokenizer=tokenizer_se,\n",
    "                        do_sample= False,\n",
    "                        max_length=64,\n",
    "                        eos_token_id= tokenizer_se.eos_token_id,\n",
    "        device=0 if int(os.environ.get(\"LOCAL_RANK\", 0)) == 0 else -1,)\n",
    "    #############################e\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #########################b\n",
    "\n",
    "    ds = load_dataset(\"json\", data_files=\"/root/autodl-tmp/BIG-Bench-Hard/bbh/navigate.json\",field=\"examples\")['train']\n",
    "    ds_split=ds.train_test_split(test_size=0.2)\n",
    "    \n",
    "    answer_all=ds['target']\n",
    "    \n",
    "    prompt_all=ds['input']\n",
    "    prompt_train=ds_split['train']['input']\n",
    "    prompt_test=ds_split['test']['input']\n",
    "\n",
    "    \n",
    "    prompt_all_cot= ['[{}] Let’ s think step by step.'.format(prompt.replace('\\n', ' ')) for prompt in prompt_all]\n",
    "    prompt_test_cot= ['[{}] Let’ s think step by step.'.format(prompt.replace('\\n', ' ')) for prompt in prompt_test]\n",
    "    prompt_train_cot= ['[{}] Let’ s think step by step.'.format(prompt.replace('\\n', ' ')) for prompt in prompt_train]    \n",
    "\n",
    "    ##########################e\n",
    "\n",
    "\n",
    "    trlx.train(\n",
    "        prompts=prompt_train_cot,\n",
    "        eval_prompts=prompt_test_cot,\n",
    "        reward_fn=reward_se,\n",
    "        #metric_fn=metric_se,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    hparams = {} if len(sys.argv) == 1 else json.loads(sys.argv[1])\n",
    "    \n",
    "    main(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea35a149-2e8d-4278-81d1-83fb918f0e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    def reward_se( prompts: List[str], outputs: List[str], **kwargs) -> List[float]:\n",
    "\n",
    "        rewards = []\n",
    "        for q, a in zip(prompts, outputs):\n",
    "            feedback_prompt = f'Is the answer to the question correct? The question is: {q}. The answer is: {a}'\n",
    "            feedback = se_generator(feedback_prompt)[0]['generated_text']  # Assuming 'model' is your trained T5 model\n",
    "            feedback = feedback.lower().strip()\n",
    "            print(feedback)\n",
    "            reward = 0.0 \n",
    "            if 'yes' in feedback:\n",
    "                reward = 1.0 \n",
    "                \n",
    "            elif 'no' in feedback:\n",
    "                reward = -1.0\n",
    "\n",
    "            rewards.append(reward)\n",
    "        return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "451350d0-e3fd-442a-a39e-4b350f1035eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, pipeline\n",
    "    \n",
    "    # Load the model\n",
    "model_se_0 = T5ForConditionalGeneration.from_pretrained(\"/root/autodl-tmp/flan-t5-large\")\n",
    "\n",
    "    # Load the tokenizer\n",
    "tokenizer_se = T5Tokenizer.from_pretrained(\"/root/autodl-tmp/flan-t5-large\")\n",
    "\n",
    "    # Create the pipeline\n",
    "se_generator= pipeline(\"text2text-generation\", model=model_se_0, tokenizer=tokenizer_se,\n",
    "                        do_sample= True,\n",
    "                        top_k= 50,\n",
    "                        top_p= 0.95,\n",
    "                        max_length=100,\n",
    "                        eos_token_id= -1,\n",
    "                        temperature= 1.0,\n",
    "                          device=0 if int(os.environ.get(\"LOCAL_RANK\", 0)) == 0 else -1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e940654-2465-4347-9fa4-9d1804b1dd5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /root/autodl-tmp/msc_ml/t5_large_checkpoints were not used when initializing T5ForConditionalGeneration: ['v_head.0.weight', 'v_head.2.bias', 'v_head.0.bias', 'v_head.2.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "    # Load the model\n",
    "model_se_1 = T5ForConditionalGeneration.from_pretrained(\"/root/autodl-tmp/msc_ml/t5_large_checkpoints\")\n",
    "\n",
    "\n",
    "\n",
    "    # Create the pipeline\n",
    "se_generator_1 = pipeline(\"text2text-generation\", model=model_se_1, tokenizer=tokenizer_se,\n",
    "                        do_sample= True,\n",
    "                        top_k= 50,\n",
    "                        top_p= 0.95,\n",
    "                        max_length=100,\n",
    "                        eos_token_id= -1,\n",
    "                        temperature= 1.0,\n",
    "                        device=0 if int(os.environ.get(\"LOCAL_RANK\", 0)) == 0 else -1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd856374-a11a-4dbb-9143-9f3f99beb225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/root/.cache/huggingface/datasets/json/default-e5badb54ef3cd267/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7589b27463b5470382554b203072e892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"json\", data_files=\"/root/autodl-tmp/BIG-Bench-Hard/bbh/navigate.json\",field=\"examples\")['train']\n",
    "ds_split=ds.train_test_split(test_size=0.2)\n",
    "prompt_all=ds['input']\n",
    "prompt_all_new= [prompt.replace('\\n', ' ') for prompt in prompt_all]\n",
    "prompt_all_new=['[{}] Let’ s think step by step.'.format(prompt.replace('\\n', ' ')) for prompt in prompt_all_new]\n",
    "answer_all=ds['target']\n",
    "prompt_train=ds_split['train']['input']\n",
    "prompt_test=ds_split['test']['input']\n",
    "answer_test=ds_split['test']['target']\n",
    "answer_train=ds_split['train']['target']\n",
    "\n",
    "\n",
    "\n",
    "prompt_test_new= ['[{}] Let’ s think step by step.'.format(prompt.replace('\\n', ' ')) for prompt in prompt_test]\n",
    "prompt_train_new= ['[{}] Let’ s think step by step.'.format(prompt.replace('\\n', ' ')) for prompt in prompt_train]\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def accuracy(prompts: List[str], outputs: List[str]) -> Dict[str, List[float]]:\n",
    "    match=[]\n",
    "        \n",
    "    for i,prompt in enumerate(prompts):\n",
    "\n",
    "        index = prompt_all_new.index(prompt)\n",
    "        if outputs[i].lower().strip()==answer_all[index].lower().strip():\n",
    "            is_correct=1.0\n",
    "        else:\n",
    "            is_correct=0.0\n",
    "                \n",
    "        match.append(is_correct)\n",
    "\n",
    "    return sum(match)/len(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c5dc472-2b96-4047-b477-5315f60eb4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "outputs_0=[]\n",
    "for i in range(len(prompt_train)):\n",
    "    \n",
    "    question=prompt_train[i]\n",
    "    answer=answer_train[i]\n",
    "    #print('££££££££££££££££££££££££££',question)\n",
    "    generation=se_generator(question)[0]['generated_text']\n",
    "    outputs_0.append(generation)\n",
    "    #print('$$$$$$$$$$$$$',generation)\n",
    "    #print('============',answer)\n",
    "    #print(reward_fn(prompts=[question], outputs=[generation]))\n",
    "    \n",
    "outputs_1=[]\n",
    "for i in range(len(prompt_train)):\n",
    "    \n",
    "    question=prompt_train[i]\n",
    "    answer=answer_train[i]\n",
    "    #print('££££££££££££££££££££££££££',question)\n",
    "    generation=se_generator_1(question)[0]['generated_text']\n",
    "    outputs_1.append(generation)\n",
    "    #print('$$$$$$$$$$$$$',generation)\n",
    "    #print('============',answer)\n",
    "    #print(reward_fn(prompts=[question], outputs=[generation]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b1947c0-aaf2-45c7-b044-f7207c1be3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(prompts: List[str], outputs: List[str]) -> Dict[str, List[float]]:\n",
    "    match=[]\n",
    "        \n",
    "    for i,prompt in enumerate(prompts):\n",
    "        generation=''\n",
    "        if 'yes' in outputs[i].lower().strip():\n",
    "            generation='yes'\n",
    "        elif 'no' in outputs[i].lower().strip():\n",
    "            generation='no'\n",
    "            \n",
    "\n",
    "        index = prompt_all_new.index(prompt)\n",
    "        if generation==answer_all[index].lower().strip():\n",
    "            is_correct=1.0\n",
    "        else:\n",
    "            is_correct=0.0\n",
    "                \n",
    "        match.append(is_correct)\n",
    "\n",
    "    return sum(match)/len(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddbc85da-f8db-4862-b8c6-124e1c76f990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.455\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "accuracy_0=accuracy(prompt_train_new,outputs_0)\n",
    "print(accuracy_0)\n",
    "accuracy_1=accuracy(prompt_train_new,outputs_1)\n",
    "print(accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "784ec4b2-a729-4369-9a02-45c8df27b38e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d793b0-5bf9-4aa5-a0bb-d24700dcf85f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
